name: scrape_big5
on:
  workflow_dispatch:
jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: 'write'
      id-token: 'write'
    steps:
      - name: Check out this repo
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Installed package list
        run: apt list --installed

      - name: Remove default Chromium
        run: sudo apt purge chromium-browser

      - name: Install a new Chromium
        run: sudo apt install -y chromium-browser

      - name: Install all necessary packages
        run: pip install -r requirements.txt

      - id: 'auth'
        uses: 'google-github-actions/auth@v1'
        with:
          workload_identity_provider: '${{ secrets.GCP_WIP }}'
          service_account: '${{ secrets.GCP_SERVICE_ACCOUNT }}'

      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v1'

      - name: Run the scraping script (first 5 leagues)
        env: 
          GCP_PROJECT_NAME: ${{ secrets.GCP_PROJECT_NAME }}
        run: python scraper.py --leagues "EPL" "La Liga" "Serie A" "Ligue 1" "Bundesliga" --write_type "WRITE_TRUNCATE"

      - name: Commit and push if it changed
        run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push
