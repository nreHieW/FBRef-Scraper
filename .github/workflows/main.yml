name: scrape_fbref
on:
  workflow_dispatch:
jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: 'write'
      id-token: 'write'
    steps:
      - name: Check out this repo
        uses: actions/checkout@v3

      - name: Install uv
        uses: astral-sh/setup-uv@v6

      - name: Set up Python
        run: uv python install

      - name: setup-chromedriver
        uses: nanasess/setup-chromedriver@v2.2.1    

      - name: Install the project
        run: uv sync --locked --all-extras --dev

      - id: 'auth'
        uses: 'google-github-actions/auth@v1'
        with:
          workload_identity_provider: '${{ secrets.GCP_WIP }}'
          service_account: '${{ secrets.GCP_SERVICE_ACCOUNT }}'

      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v1'

      - name: Run the scraping script (first 5 leagues)
        env: 
          GCP_PROJECT_NAME: ${{ secrets.GCP_PROJECT_NAME }}
        run: uv run stats_scraper.py --write_type "WRITE_TRUNCATE" --start 2022 --end 2025
      
      - name: Commit and Push The Results
        run: |
         git config --global user.name "github-actions[bot]"
         git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
         git add -A
         timestamp=$(date -u)
         git commit -m "Latest data: ${timestamp}" || exit 0
         git push
